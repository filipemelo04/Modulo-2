{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão logística: Scikit-learn sobre dataset Iris\n",
    "\n",
    "## O que vamos fazer?\n",
    "- Descarregar o dataset Iris.\n",
    "- Pré-processar o dataset usando métodos de Scikit-learn.\n",
    "- Formar um modelo de classificação multiclasse por validação cruzada com Scikit-learn.\n",
    "\n",
    "Agora vamos resolver o mesmo modelo usando métodos de Scikit-learn. \n",
    "\n",
    "Pode ter como referência este exemplo: [Logistic regression 3-class classifier](https://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar todos os módulos necessários para esta célula\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar o dataset Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Carregar o dataset Iris como arrays X e Y\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "Pré-processar os dados com métodos de Scikit-learn, do mesmo modo que fez no exercício de Scikit-learn de regressão linear:\n",
    "\n",
    "- Reordená-los aleatoriamente. \n",
    "- Normalizar, se necessário.\n",
    "- Dividi-los em subsets de formação e testes\n",
    "\n",
    "Nesta ocasião, de novo, iremos fazer a validação cruzada por K-fold, já que o dataset é muito pequeno (150 exemplos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9, 3.1, 5.4, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.6, 2.8, 4.9, 2. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Reordenar os dados aleatoriamente\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 2, 1, 1, 2, 0, 2, 0, 1, 1, 0, 0, 0, 2, 0, 2, 0, 1, 1,\n",
       "       2, 0, 0, 2, 1, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 2,\n",
       "       2, 2, 0, 2, 1, 2, 2, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 1, 0, 0, 2, 2,\n",
       "       2, 1, 2, 0, 2, 1, 2, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       2, 2, 1, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1, 2, 1, 1,\n",
       "       0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 2, 2, 1, 1, 2, 2, 0, 0, 0,\n",
       "       0, 1, 1, 1, 2, 1, 1, 1, 0, 2, 1, 2, 2, 2, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Normalizar, se necessário\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividi-los em subsets de formação e testes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar um modelo inicial\n",
    "- Formar um modelo inicial sobre o subset de formação sem regularização. \n",
    "- Comprovar a idoneidade do modelo e voltar a formá-lo se necessário.\n",
    "\n",
    "A função de Scikit-learn que pode utilizar é [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) com esquema OvR (“one-vs-rest”, uma classe contra o resto).\n",
    "\n",
    "Avaliar sobre o subset de teste com o seu método de *score()*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de treino: 0.9\n",
      "Score de teste: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# TODO: Formar o seu modelo no subconjunto de formação não regularizada e avaliar sobre o de teste\n",
    "\n",
    "clf = LogisticRegression(random_state=42, multi_class='ovr').fit(X_train, y_train)\n",
    "print(\"Score de treino:\", clf.score(X_train, y_train))\n",
    "print(\"Score de teste:\", clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar a regularização ótima através de validação cruzada\n",
    "- Formar um modelo por cada valor de regularização a considerar.\n",
    "- Forma-os e avalia-os sobre um fold do subset de formação usando K-fold. \n",
    "- Escolher o modelo e a sua regularização ótima.\n",
    "\n",
    "O método LogisticRegression aplica por defeito uma regularização L2 por defeito, mas podemos dar-lhe um valor de *C* determinado. *C* atua como o inverso do fator de regularização *lambda*, pelo que os valores menores, maior regularização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score ( CS:, 10.0 , ): 0.93\n",
      "score ( CS:, 100.0 , ): 0.9\n",
      "score ( CS:, 1000.0 , ): 0.9\n",
      "score ( CS:, 10000.0 , ): 0.97\n",
      "score ( CS:, 99999.99999999999 , ): 0.83\n",
      "Acurácias em cada fold: [0.93, 0.9, 0.9, 0.97, 0.83]\n",
      "Acurácia média: 0.906\n"
     ]
    }
   ],
   "source": [
    "# TODO: Formar um modelo diferente por cada C sobre um fold de K-fold diferente\n",
    "\n",
    "# Usar os valores de lambda que considerávamos em exercícios anteriores\n",
    "lambdas = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "# Calcular o C correspondente a cada um\n",
    "cs = [1/l if l != 0 else 0 for l in lambdas]\n",
    "\n",
    "# Criar 5 splits de K-fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterar sobre os 5 splits, para os seus modelos e avalia-os no subset do CV gerado\n",
    "log_models = [] \n",
    "best_model = None\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    model = LogisticRegression(random_state=42, multi_class='ovr', C=cs[i])\n",
    "    model.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    print(\"score (\", \"CS:,\", cs[i], \",\",  \"):\", round(score, 2))\n",
    "    log_models.append(round(score, 2))\n",
    "\n",
    "print(\"Acurácias em cada fold:\", log_models)\n",
    "print(\"Acurácia média:\", np.mean(log_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cs: 10.0\n",
      "[1.         0.93333333 0.86666667 0.93333333 0.96666667]\n",
      "Score: 0.9400000000000001\n",
      "\n",
      "Cs: 100.0\n",
      "[1.         0.93333333 0.86666667 1.         0.96666667]\n",
      "Score: 0.9533333333333334\n",
      "\n",
      "Cs: 1000.0\n",
      "[1.         0.93333333 0.9        1.         0.96666667]\n",
      "Score: 0.96\n",
      "\n",
      "Cs: 10000.0\n",
      "[1.         0.93333333 0.93333333 1.         0.93333333]\n",
      "Score: 0.96\n",
      "\n",
      "Cs: 99999.99999999999\n",
      "[1.         0.93333333 0.93333333 1.         0.93333333]\n",
      "Score: 0.96\n",
      "\n",
      "Acurácias em cada fold: [0.94, 0.9533, 0.96, 0.96, 0.96]\n",
      "Acurácia média: 0.95466\n"
     ]
    }
   ],
   "source": [
    "# TODO: Formar um modelo diferente por cada C sobre um fold de K-fold diferente\n",
    "\n",
    "# Usar os valores de lambda que considerávamos em exercícios anteriores\n",
    "lambdas = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "# Calcular o C correspondente a cada um\n",
    "cs = [1/l if l != 0 else 0 for l in lambdas]\n",
    "\n",
    "# Iterar sobre os 5 splits, para os seus modelos e avalia-os no subset do CV gerado\n",
    "log_models = [] \n",
    "best_model = None\n",
    "\n",
    "for c in cs:\n",
    "    model = LogisticRegression(random_state=42, multi_class='ovr', C=c)\n",
    "    scores = cross_val_score(model, X, Y, cv=5, scoring='accuracy')\n",
    "    score = np.mean(scores)\n",
    "    print(\"Cs:\", c)\n",
    "    print(scores)\n",
    "    print(\"Score:\", score)\n",
    "    print()\n",
    "    log_models.append(round(score, 4))\n",
    "\n",
    "print(\"Acurácias em cada fold:\", log_models)\n",
    "print(\"Acurácia média:\", np.mean(log_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo finalmente sobre o subset de teste\n",
    "\n",
    "- Mostrar os coeficientes e intercept do melhor modelo. \n",
    "- Avaliar o melhor modelo sobre o subset de teste inicial.\n",
    "- Calcular os acertos e falhas no subset de teste e representá-los graficamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes de intercept do modelo formado\n",
      "Intercept: 4.873147279056489   Coeficientes: [ -5.13115864  12.12528881 -14.7650884  -14.17847747]\n",
      "\n",
      "y_test_pred [2 0 1 1 0 1 1 1 1 2 1 1 0 2 1 2 0 0 1 1 1 2 0 1 2 0 0 0 2 2]\n",
      "y_test [2 0 1 1 0 2 1 1 1 1 1 1 0 2 1 2 0 0 1 1 1 2 0 1 2 0 0 0 2 2]\n",
      "Mean Accuracy: 0.93\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Avaliar o melhor modelo sobre o subset de teste inicial\n",
    "model = LogisticRegression(random_state=42, multi_class='ovr', C=cs[-1])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar os coeficientes e intercept do melhor modelo formado\n",
    "print('Coeficientes de intercept do modelo formado')\n",
    "print(\"Intercept:\", model.intercept_[0], \"  Coeficientes:\", model.coef_[0])  # Mostrar o intercept como o primeiro coeficiente\n",
    "print()  \n",
    "    \n",
    "# Realizar as previsões sobre o subset de teste\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"y_test_pred\", y_test_pred)\n",
    "print(\"y_test\", y_test)\n",
    "\n",
    "# Calcular a métrica de avaliação do modelo de precisão (“accuracy”) média (o seu método score())\n",
    "mean_accuracy = model.score(X_test, y_test)\n",
    "print(\"Mean Accuracy: %.2f\" % mean_accuracy)\n",
    "\n",
    "# Calcular os acertos e falhas no subset de teste e representá-los graficamente\n",
    "results = y_test - y_test_pred\n",
    "\n",
    "# Representar graficamente\n",
    "plt.figure(1)\n",
    "\n",
    "plt.scatter(range(len(results)), results)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
