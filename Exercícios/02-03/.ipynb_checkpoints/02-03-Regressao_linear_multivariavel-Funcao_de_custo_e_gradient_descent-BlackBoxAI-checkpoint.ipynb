{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão linear multivariável: Função de custo e gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que vamos fazer?\n",
    "\n",
    "- Implementar a função de custo para regressão linear multivariável \n",
    "- Implementar a otimização da função de custo por gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 1: Implementar a função de custo para regressão linear multivariável\n",
    "\n",
    "Nesta tarefa, deve implementar a função de custo para regressão linear multivariável em Python usando o Numpy. A função de \n",
    "custo deve seguir a função incluída nos diapositivos e no manual do curso.\n",
    "\n",
    "Para o fazer, preencher o código na seguinte célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO: Implementar a função de custo utilizando o seguinte modelo\n",
    "\n",
    "def cost_function(x, y, theta):\n",
    "    \"\"\" Computar a função de custo para o dataset e coeficientes considerados.\n",
    "    \n",
    "    Argumentos posicionais:\n",
    "    x -- array 2D de Numpy com os valores das variáveis independentes dos exemplos, de tamanho m x n \n",
    "    y -- array 1D Numpy com a variável dependente/objetivo, de tamanho m x 1\n",
    "    theta -- array 1D Numpy com os pesos dos coeficientes do modelo, de tamanho 1 x n (vetor fila)\n",
    "    \n",
    "    Devolver:j -- float com o custo para esse array theta \n",
    "    \"\"\"\n",
    "    # Verificar se os dados estão de acordo\n",
    "    if not (x.ndim == 2 and theta.ndim == 1 and y.ndim == 1): \n",
    "        return False\n",
    "    \n",
    "    m = len(y)\n",
    "\n",
    "    # Calcular o produto escalar entre x e theta\n",
    "    h = np.dot(x, theta.T)  \n",
    "    \n",
    "    # Calculando a função de custo\n",
    "    j = (1 / (2 * m)) * np.sum((h - y) ** 2)  \n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprovar a sua implementação, recuperar o seu código do notebook anterior sobre datasets sintéticos e seguir as \n",
    "instruções abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta a estimar\n",
      "Theta shape: (3,)\n",
      "[43.89714207  7.84563813  2.53507434]\n",
      "Primeiras 10 filas e 5 colunas de X e Y:\n",
      "X:\n",
      " [[-0.56228753 -1.01283112  0.31424733]\n",
      " [ 0.79103195 -0.90938745  1.40279431]\n",
      " [-0.90802408 -1.4123037   1.46564877]\n",
      " [ 0.09176078 -1.98756891 -0.21967189]\n",
      " [ 0.21645859  0.04557184 -0.65160035]\n",
      " [-1.37766937 -0.93782504  0.51503527]\n",
      " [-0.2257763   0.0675282  -1.42474819]\n",
      " [ 0.68626019 -1.61271587 -0.47193187]\n",
      " [-0.03582604  1.56464366 -2.6197451 ]\n",
      " [ 0.2766908   0.82718325  0.01300189]]\n",
      "\n",
      "Y:\n",
      " [-31.83248167  31.14550473 -47.22455704 -12.12259519   8.2075983\n",
      " -66.52793118 -12.99297505  16.27569357   4.06171861  18.66867653]\n",
      "\n",
      "\n",
      "Dimensões de X e Y:\n",
      "X shape: (80, 3)\n",
      "Y shape: (80,)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Gerar um dataset sintético, sem termo de erro, sob a forma que escolher\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Gerar dados de regressão linear multivariável\n",
    "X, Y, Theta_verd = make_regression(n_samples=80,  # Número de amostras\n",
    "                              n_features=3,  # Número de variáveis independentes (features)\n",
    "                              noise=0,       # Sem ruído\n",
    "                              coef=True,     # Retorna os coeficientes verdadeiros\n",
    "                              random_state=42)  # Para resultados reprodutíveis\n",
    "\n",
    "# Comprovar os valores e dimensões (forma ou \"shape\") dos vetores\n",
    "print('Theta a estimar') \n",
    "print(\"Theta shape:\", Theta_verd.shape)\n",
    "print(Theta_verd)\n",
    "\n",
    "print('Primeiras 10 filas e 5 colunas de X e Y:') \n",
    "print('X:\\n', X[:10])  # Primeiras 10 linhas e até 5 colunas de X\n",
    "print()\n",
    "print('Y:\\n', Y[:10])  # Primeiros 10 valores de Y\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensões de X e Y:') \n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que o dataset sintético não tem termo de erro, a função de custo para o theta correto deve ser exatamente 0, aumentando \n",
    "o seu valor à medida que nos afastamos do mesmo.\n",
    "\n",
    "Comprovar a sua implementação da função de custo comprovando o seu valor com diferentes valores do seu argumento theta, \n",
    "comprovando vários valores desde o Theta errado até valores mais afastados do mesmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo do modelo:\n",
      "0.0\n",
      "Theta real:\n",
      "[43.89714207  7.84563813  2.53507434]\n",
      "\n",
      "Custo com o theta errado:\n",
      "482.4341600807497\n",
      "Theta errado:\n",
      "[5 2 3]\n"
     ]
    }
   ],
   "source": [
    "#TODO: Comprovar a implementação da sua função de custos\n",
    "\n",
    "# Verificando a função de custo com valores de theta reais\n",
    "j = cost_function(X, Y, Theta_verd)\n",
    "\n",
    "print('Custo do modelo:') \n",
    "print(j)\n",
    "print('Theta real:') \n",
    "print(Theta_verd)\n",
    "\n",
    "# Verificando a função de custo com valores de theta aleatórios\n",
    "theta_errado = np.array([5, 2, 3])  # Um theta dado aleatpriamente\n",
    "j_errado = cost_function(X, Y, theta_errado)\n",
    "\n",
    "print('\\nCusto com o theta errado:')\n",
    "print(j_errado)\n",
    "print('Theta errado:') \n",
    "print(theta_errado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2: Implementar a otimização desta função de custo por gradient descent\n",
    "\n",
    "Agora vamos resolver a otimização dessa função de custo para formar o modelo, mediante o método de gradient descent. O \n",
    "modelo será considerado formado quando a sua função de custo tiver atingido um valor mínimo.\n",
    "\n",
    "Para o fazer, preencher novamente o modelo do código na seguinte célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar a função que forma o modelo por gradient descent\n",
    "import math\n",
    "\n",
    "def gradient_descent(x, y, theta, alpha, e=math.e, iter=5000):\n",
    "    \n",
    "    \"\"\" Formar o modelo otimizando a sua função de custo por gradient descent\n",
    "    \n",
    "    Argumentos posicionais:\n",
    "    x -- array 2D de Numpy com os valores das variáveis independentes dos exemplos, de tamanho m x n \n",
    "    y -- array 1D Numpy com a variável dependente/objetivo, de tamanho m x 1\n",
    "    theta -- array 1D Numpy com os pesos dos coeficientes do modelo, de tamanho 1 x n (vetor fila) \n",
    "    alpha -- float, ratio de formação\n",
    "    \n",
    "    Argumentos numerados (keyword):\n",
    "    e -- float, diferença mínima entre iterações para declarar que a formação finalmente convergiu \n",
    "    iter_ -- int/float, número de iterações\n",
    "    \n",
    "    Devolver:\n",
    "    j_hist -- list/array com a evolução da função de custo durante a formação \n",
    "    theta -- array Numpy com o valor do theta na última iteração\n",
    "    \"\"\"\n",
    "    # TODO: declarar valores por defeito para e e iter_ nos argumentos nomeados (palavra-chave) da função.\n",
    "    \n",
    "    iter_ = int(iter_) # Se declarou iter_ em notação científica (1e3) ou float (1000.), converter\n",
    "    \n",
    "    # Inicializar j_hist como uma list ou um array Numpy. Recordar que não sabemos que tamanho terá\n",
    "    j_hist = []\n",
    "    \n",
    "    m, n = x.shape[0], x.shape[1] # Obter m e n a partir das dimensões de X\n",
    "    \n",
    "    for k in ietr_: # Iterar sobre o número máximo de iterações\n",
    "        theta_iter = [100, 100, 100]# Declarar um theta para cada iteração, pois precisamos de a atualizar.\n",
    "        \n",
    "        for j in [...]: # Iterar sobre n.º de características\n",
    "            # Atualizar theta_iter para cada característica, de acordo com a derivada da função de custo\n",
    "            # Incluir a relação de formação alfa\n",
    "            # Cuidado com as multiplicações matriciais, a sua ordem e dimensões\n",
    "            theta_iter[j] = theta[j] - [...]\n",
    "            \n",
    "        theta = theta_iter\n",
    "            \n",
    "        cost = cost_function([...]) # Calcular o custo para a atual iteração theta\n",
    "            \n",
    "        j_hist[...] # Adicionar o custo da iteração atual ao histórico de custos\n",
    "        \n",
    "        # Comprovar se a diferença entre o custo da iteração atual e o custo da última iteração em valor \n",
    "        # absoluto são inferiores que a diferença mínima para declarar a convergência, e\n",
    "        if k > 0 and [...]:\n",
    "            print('Convergir na iteração n.º: ', k)\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        print('N.º máx. de iterações alcançado')\n",
    "        \n",
    "    return j_hist, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função BlackBox AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta, alpha, e=1e-6, iter_=1000):\n",
    "    \"\"\" Formar o modelo otimizando a sua função de custo por gradient descent\n",
    "    \n",
    "    Argumentos posicionais:\n",
    "    x -- array 2D de Numpy com os valores das variáveis independentes dos exemplos, de tamanho m x n \n",
    "    y -- array 1D Numpy com a variável dependente/objetivo, de tamanho m x 1\n",
    "    theta -- array 1D Numpy com os pesos dos coeficientes do modelo, de tamanho 1 x n (vetor fila) \n",
    "    alpha -- float, ratio de formação\n",
    "    \n",
    "    Argumentos numerados (keyword):\n",
    "    e -- float, diferença mínima entre iterações para declarar que a formação finalmente convergiu \n",
    "    iter_ -- int/float, número de iterações\n",
    "    \n",
    "    Devolver:\n",
    "    j_hist -- list/array com a evolução da função de custo durante a formação \n",
    "    theta -- array Numpy com o valor do theta na última iteração\n",
    "    \"\"\"\n",
    "    iter_ = int(iter_)  # Converter para inteiro\n",
    "    j_hist = []  # Inicializar histórico de custos\n",
    "    m, n = x.shape  # Obter m e n a partir das dimensões de X\n",
    "    \n",
    "    for k in range(iter_):  # Iterar sobre o número máximo de iterações\n",
    "        theta_iter = theta.copy()  # Copiar theta para atualização\n",
    "        \n",
    "        for j in range(n):  # Iterar sobre o número de características\n",
    "            # Atualizar theta_iter para cada característica\n",
    "            theta_iter[j] = theta[j] - (alpha / m) * np.sum((x.dot(theta) - y) * x[:, j])\n",
    "        \n",
    "        theta = theta_iter  # Atualizar theta\n",
    "        \n",
    "        cost = cost_function(x, y, theta)  # Calcular o custo para a atual iteração theta\n",
    "        j_hist.append(cost)  # Adicionar o custo da iteração atual ao histórico de custos\n",
    "        \n",
    "        # Verificar a convergência\n",
    "        if k > 0 and abs(j_hist[-1] - j_hist[-2]) < e:\n",
    "            print('Convergir na iteração n.º:', k)\n",
    "            break\n",
    "    else:\n",
    "        print('N.º máx. de iterações alcançado')\n",
    "        \n",
    "    return j_hist, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprovar a sua implementação, mais uma vez, utilizar vários valores de Theta, tanto corretos como valores cada vez mais\n",
    "afastados do mesmo, e verificar se eventualmente o modelo converge para o correto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Testar a sua implementação através da formação de um modelo no dataset sintético anteriormente criado.\n",
    "\n",
    "# Criar um theta inicial com um determinado valor.\n",
    "# Primeiro usar o valor theta correto, depois cada vez mais valores periféricos.\n",
    "# Finalmente, testar também a sua implementação com valores theta_ini aleatórios\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:') \n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1 \n",
    "e = 1e-3\n",
    "iter_ = 1e3 # Verificar se a sua função pode suportar valores de flutuação ou modificá-los.\n",
    "\n",
    "print('Hiper-parâmetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)\n",
    "\n",
    "t = time.time()\n",
    "j_hist, theta_final = gradient_descent([...]) \n",
    "\n",
    "print('Tempo de formação (s):', time.time() - t)\n",
    "\n",
    "# TODO: completar\n",
    "print('\\nÚltimos 10 valores da função de custo') \n",
    "print(j_hist[...])\n",
    "print('\\Custo final:') \n",
    "print(j_hist[...]) \n",
    "print('\\nTheta final:') \n",
    "print(theta_final)\n",
    "\n",
    "print('Valores verdadeiros de Theta e diferença com valores formados:') \n",
    "print(Theta_verd)\n",
    "print(theta_final - Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representar a função de custo\n",
    "\n",
    "Representar graficamente o histórico da função de custo para comprovar a sua implementação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TOOD: Representar graficamente a função de custo vs. o n.º de iterações\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.title('Função de custo') \n",
    "plt.xlabel('nº iterações') \n",
    "plt.ylabel('custo')\n",
    "\n",
    "plt.plot([...]) # Completar\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprovar completamente a implementação destas funções, modificar o dataset sintético original para verificar se a função \n",
    "de custo e a formação de gradient descent ainda a funcionar corretamente\n",
    "\n",
    "Por exemplo, modificar o número de exemplos e o número de características\n",
    "\n",
    "Acrescentar também uma vez mais um termo de erro ao Y. Neste caso, o Theta inicial e o final podem não corresponder exatamente, pois introduzimos erro ou “ruído” no dataset de formação.\n",
    "\n",
    "Finalmente, verificar todos os hiper-parâmetros da sua implementação. Utilizar vários valores de alfa, e, número de iterações, etc., e comprovar se os resultados são os esperados.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
