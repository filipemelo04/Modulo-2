{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM: Scikit-learn sobre dataset Labeled Faces in the Wild\n",
    "\n",
    "## O que vamos fazer?\n",
    "- Descarregar e analisar o dataset Labeled Faces in the Wild (LFW). \n",
    "- Pré-processar o dataset.\n",
    "- Formar um modelo de classificação multiclasse com SVM por validação cruzada. \n",
    "- Avaliar a precisão do modelo e representá-la graficamente\n",
    "\n",
    "O dataset Labeled Faces in the Wild (LFW) é um dos datasets mais usados como exemplo e para avaliar os nossos modelos e algoritmos. É um dataset muito curioso: é uma coleção de fotos de rostos de famosos (em formato JPEG) com 13 233 exemplos, 5 749 classes (rostos de famosos) e 5 828 características (pixeis).\n",
    "\n",
    "Toda a informação está na sua página de internet oficial: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "Habitualmente usamos o dataset em 2 tipos de tarefas ou modelos diferentes de classificação:\n",
    "- Verificação de faces: num conjunto de 2 fotografias, um modelo de classificação binária deve prever se é a mesma pessoa.\n",
    "- Reconhecimento facial: numa fotografia, o modelo deve classificá-la como pertencendo a um dos famosos identificados (classes).\n",
    "\n",
    "\n",
    "A sua tarefa será criar um modelo SVM para resolver a tarefa de reconhecimento facial, otimizar os seus hiper-parâmetros por validação cruzada e avaliá-lo.\n",
    "\n",
    "*Vamos formar um modelo ML que seja capaz de reconhecer rostos de famosos!*\n",
    "\n",
    "Referências:\n",
    "- [The Labeled Faces in the Wild face recognition dataset](https://scikit-learn.org/stable/datasets/index.html#labeled-faces-in-the-wild-dataset)\n",
    "- [sklearn.datasets.fetch_lfw_people](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html)\n",
    "- [sklearn.datasets.fetch_lfw_pairs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_pairs.html)\n",
    "- [Faces recognition example using eigenfaces and SVMs](https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar de todos os módulos necessários para esta célula\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from time import time\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar o dataset LFW\n",
    "\n",
    "Representar graficamente alguns dos exemplos e as suas classes ou números associados.\n",
    "\n",
    "*Nota*: Cuidado com o seu tamanho! Se for um dataset demasiado grande para o seu ambiente, pode reduzir o seu tamanho escolhendo um número de exemplos mais reduzido ao acaso, reordenando aleatoriamente os exemplos para evitar ter classes/faces com um número baixo de exemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foi reduzido o Dataset, devido ao facto de ser muito extenso. Apenas faces com no minimo 20 exemplos foram escolhidas e cada imagem foi redimensionada para 30% do tamanho original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exitem 3023 exemplos\n",
      "A imagem tem de tamanho 62 x 47.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Carregar o dataset Digits como arrays X e Y e representar alguns dos exemplos\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=20)#, resize=0.4)  # redimensiona as imagens para 30% do tamanho original\n",
    "\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "print(f\"Exitem {n_samples} exemplos\")\n",
    "print(f\"A imagem tem de tamanho {h} x {w}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamnho do dataset: (3023, 2914)\n",
      "Número de classes: 62\n",
      "Nome das pessoas: ['Alejandro Toledo' 'Alvaro Uribe' 'Amelie Mauresmo' 'Andre Agassi'\n",
      " 'Angelina Jolie' 'Ariel Sharon' 'Arnold Schwarzenegger'\n",
      " 'Atal Bihari Vajpayee' 'Bill Clinton' 'Carlos Menem' 'Colin Powell'\n",
      " 'David Beckham' 'Donald Rumsfeld' 'George Robertson' 'George W Bush'\n",
      " 'Gerhard Schroeder' 'Gloria Macapagal Arroyo' 'Gray Davis'\n",
      " 'Guillermo Coria' 'Hamid Karzai' 'Hans Blix' 'Hugo Chavez' 'Igor Ivanov'\n",
      " 'Jack Straw' 'Jacques Chirac' 'Jean Chretien' 'Jennifer Aniston'\n",
      " 'Jennifer Capriati' 'Jennifer Lopez' 'Jeremy Greenstock' 'Jiang Zemin'\n",
      " 'John Ashcroft' 'John Negroponte' 'Jose Maria Aznar'\n",
      " 'Juan Carlos Ferrero' 'Junichiro Koizumi' 'Kofi Annan' 'Laura Bush'\n",
      " 'Lindsay Davenport' 'Lleyton Hewitt' 'Luiz Inacio Lula da Silva'\n",
      " 'Mahmoud Abbas' 'Megawati Sukarnoputri' 'Michael Bloomberg' 'Naomi Watts'\n",
      " 'Nestor Kirchner' 'Paul Bremer' 'Pete Sampras' 'Recep Tayyip Erdogan'\n",
      " 'Ricardo Lagos' 'Roh Moo-hyun' 'Rudolph Giuliani' 'Saddam Hussein'\n",
      " 'Serena Williams' 'Silvio Berlusconi' 'Tiger Woods' 'Tom Daschle'\n",
      " 'Tom Ridge' 'Tony Blair' 'Vicente Fox' 'Vladimir Putin' 'Winona Ryder']\n"
     ]
    }
   ],
   "source": [
    "X = lfw_people.data\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "\n",
    "print(\"Tamnho do dataset:\", X.shape)\n",
    "print(\"Número de classes:\", len(target_names))\n",
    "print(\"Nome das pessoas:\", target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22091503, 0.26013073, 0.47450984, ..., 0.07189543, 0.0627451 ,\n",
       "        0.08366013],\n",
       "       [0.26797387, 0.34509805, 0.26666668, ..., 0.03267974, 0.03137255,\n",
       "        0.03006536],\n",
       "       [0.07189543, 0.06013072, 0.05228758, ..., 0.06535948, 0.09019608,\n",
       "        0.1006536 ],\n",
       "       [0.3137255 , 0.5882353 , 0.7908497 , ..., 0.54509807, 0.5568628 ,\n",
       "        0.5620915 ],\n",
       "       [0.32287583, 0.29673204, 0.34509805, ..., 0.351634  , 0.3372549 ,\n",
       "        0.29150328]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "Pré-processar os dados com os métodos Scikit-learn:\n",
    "\n",
    "- Reordená-los aleatoriamente. \n",
    "- Normalizar, se necessário.\n",
    "- Dividi-los em subsets de formação e testes.\n",
    "\n",
    "Nesta ocasião, mais uma vez, faremos a validação cruzada por K-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05490196, 0.08496732, 0.1006536 , ..., 0.3006536 , 0.34901962,\n",
       "        0.3503268 ],\n",
       "       [0.54771245, 0.51372546, 0.51111114, ..., 0.05490196, 0.05751634,\n",
       "        0.05751634],\n",
       "       [0.53986925, 0.53594774, 0.7267974 , ..., 0.18039216, 0.13986929,\n",
       "        0.24444444],\n",
       "       [0.19477125, 0.24444444, 0.29281047, ..., 0.32287583, 0.41830066,\n",
       "        0.2771242 ],\n",
       "       [0.36078432, 0.33202615, 0.29542485, ..., 0.54771245, 0.68235296,\n",
       "        0.8104575 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Reordenar os dados aleatoriamente\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05511811, 0.08530184, 0.10104987, ..., 0.3006536 , 0.34901962,\n",
       "        0.3503268 ],\n",
       "       [0.5498688 , 0.515748  , 0.5131234 , ..., 0.05490196, 0.05751634,\n",
       "        0.05751634],\n",
       "       [0.5419947 , 0.53805774, 0.7296588 , ..., 0.18039216, 0.13986929,\n",
       "        0.24444444],\n",
       "       ...,\n",
       "       [0.12335958, 0.05511811, 0.02230971, ..., 0.38300654, 0.5045752 ,\n",
       "        0.57908493],\n",
       "       [0.1456693 , 0.24671917, 0.4238845 , ..., 0.30718955, 0.29673204,\n",
       "        0.28235295],\n",
       "       [0.18766405, 0.20341207, 0.23228346, ..., 0.16862746, 0.19346406,\n",
       "        0.19738562]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Normalizar, se necessário\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividi-los em subsets de formação e testes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar um modelo de classificação por SVM inicial\n",
    "\n",
    "Para comprovar o funcionamento do nosso classificador SVC antes de o otimizar por validação cruzada, vamos formar um modelo inicial sobre o subset de formação e validá-lo sobre o subset de teste.\n",
    "\n",
    "Recordar usar a função [decision_function_shape](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification) para usar o esquema “um contra o resto” (“ovr”). \n",
    "\n",
    "Usar os valores por defeito de *C* e *gamma* para não influir sobre a sua regularização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 14.045s\n"
     ]
    }
   ],
   "source": [
    "model = SVC(decision_function_shape='ovr')\n",
    "t0 = time()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo no subset de teste\n",
    "Neste caso, não vamos representar a matriz de confusão, pois com 5749 classes seria demasiado grande para o analisar num gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 5.012s\n"
     ]
    }
   ],
   "source": [
    "# TODO: Avaliar o modelo com o seu score () no subset de teste.\n",
    "t1 = time()\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4193121693121693\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Então concluimos que, provavelmente por usar os valores por defeito de C e gamma, não obteve um bom resultado de accuracy nomeadamente de 0.42."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
