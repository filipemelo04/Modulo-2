{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM: Scikit-learn sobre dataset Labeled Faces in the Wild\n",
    "\n",
    "## O que vamos fazer?\n",
    "- Descarregar e analisar o dataset Labeled Faces in the Wild (LFW). \n",
    "- Pré-processar o dataset.\n",
    "- Formar um modelo de classificação multiclasse com SVM por validação cruzada. \n",
    "- Avaliar a precisão do modelo e representá-la graficamente\n",
    "\n",
    "O dataset Labeled Faces in the Wild (LFW) é um dos datasets mais usados como exemplo e para avaliar os nossos modelos e algoritmos. É um dataset muito curioso: é uma coleção de fotos de rostos de famosos (em formato JPEG) com 13 233 exemplos, 5 749 classes (rostos de famosos) e 5 828 características (pixeis).\n",
    "\n",
    "Toda a informação está na sua página de internet oficial: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "Habitualmente usamos o dataset em 2 tipos de tarefas ou modelos diferentes de classificação:\n",
    "- Verificação de faces: num conjunto de 2 fotografias, um modelo de classificação binária deve prever se é a mesma pessoa.\n",
    "- Reconhecimento facial: numa fotografia, o modelo deve classificá-la como pertencendo a um dos famosos identificados (classes).\n",
    "\n",
    "\n",
    "A sua tarefa será criar um modelo SVM para resolver a tarefa de reconhecimento facial, otimizar os seus hiper-parâmetros por validação cruzada e avaliá-lo.\n",
    "\n",
    "*Vamos formar um modelo ML que seja capaz de reconhecer rostos de famosos!*\n",
    "\n",
    "Referências:\n",
    "- [The Labeled Faces in the Wild face recognition dataset](https://scikit-learn.org/stable/datasets/index.html#labeled-faces-in-the-wild-dataset)\n",
    "- [sklearn.datasets.fetch_lfw_people](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html)\n",
    "- [sklearn.datasets.fetch_lfw_pairs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_pairs.html)\n",
    "- [Faces recognition example using eigenfaces and SVMs](https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar de todos os módulos necessários para esta célula\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from time import time\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar o dataset LFW\n",
    "\n",
    "Representar graficamente alguns dos exemplos e as suas classes ou números associados.\n",
    "\n",
    "*Nota*: Cuidado com o seu tamanho! Se for um dataset demasiado grande para o seu ambiente, pode reduzir o seu tamanho escolhendo um número de exemplos mais reduzido ao acaso, reordenando aleatoriamente os exemplos para evitar ter classes/faces com um número baixo de exemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foi reduzido o Dataset, devido ao facto de ser muito extenso. Apenas faces com no minimo 50 exemplos foram escolhidas e cada imagem foi redimensionada para 30% do tamanho original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exitem 1560 exemplos\n",
      "A imagem tem de tamanho 50 x 37.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Carregar o dataset Digits como arrays X e Y e representar alguns dos exemplos\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=50, resize=0.4)  # redimensiona as imagens para 30% do tamanho original\n",
    "\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "print(f\"Exitem {n_samples} exemplos\")\n",
    "print(f\"A imagem tem de tamanho {h} x {w}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamnho do dataset: (1560, 1850)\n",
      "Número de classes: 12\n",
      "Nome das pessoas: ['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'\n",
      " 'Gerhard Schroeder' 'Hugo Chavez' 'Jacques Chirac' 'Jean Chretien'\n",
      " 'John Ashcroft' 'Junichiro Koizumi' 'Serena Williams' 'Tony Blair']\n"
     ]
    }
   ],
   "source": [
    "X = lfw_people.data\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "\n",
    "print(\"Tamnho do dataset:\", X.shape)\n",
    "print(\"Número de classes:\", len(target_names))\n",
    "print(\"Nome das pessoas:\", target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31764707, 0.35555556, 0.45228758, ..., 0.42222223, 0.5921569 ,\n",
       "        0.49019608],\n",
       "       [0.1385621 , 0.27450982, 0.33464053, ..., 0.23398693, 0.3267974 ,\n",
       "        0.45359477],\n",
       "       [0.33594772, 0.21830066, 0.22745098, ..., 0.69542485, 0.32026145,\n",
       "        0.303268  ],\n",
       "       [0.5555556 , 0.5542484 , 0.4392157 , ..., 0.45359477, 0.4261438 ,\n",
       "        0.43790853],\n",
       "       [0.34901962, 0.38431373, 0.3529412 , ..., 0.8928104 , 0.93202615,\n",
       "        0.94248366]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "Pré-processar os dados com os métodos Scikit-learn:\n",
    "\n",
    "- Reordená-los aleatoriamente. \n",
    "- Normalizar, se necessário.\n",
    "- Dividi-los em subsets de formação e testes.\n",
    "\n",
    "Nesta ocasião, mais uma vez, faremos a validação cruzada por K-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36601308, 0.30718955, 0.4366013 , ..., 0.8601307 , 0.8928105 ,\n",
       "        0.81830066],\n",
       "       [0.27058825, 0.25751635, 0.30849674, ..., 0.09803922, 0.09411765,\n",
       "        0.09411765],\n",
       "       [0.5372549 , 0.5647059 , 0.5764706 , ..., 0.00392157, 0.00784314,\n",
       "        0.00784314],\n",
       "       [0.01568628, 0.02222222, 0.06535948, ..., 0.2130719 , 0.20261438,\n",
       "        0.18562092],\n",
       "       [0.2379085 , 0.29542485, 0.31633988, ..., 0.530719  , 0.35555556,\n",
       "        0.2901961 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Reordenar os dados aleatoriamente\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar, se necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividi-los em subsets de formação e testes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler() # padronizar os dados para que tenham média 0 e desvio padrão 1\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, é realizada a redução de dimensionalidade nos dados de treinamento X_train e X_test, mantendo um número especificado de componentes principais, neste caso de 150, utilizando um método de cálculo aleatório e escalando os componentes para variância unitária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 150 eigenfaces from 1170 faces\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n"
     ]
    }
   ],
   "source": [
    "n_components = 150\n",
    "\n",
    "print(\n",
    "    \"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0])\n",
    ")\n",
    "pca = PCA(n_components=n_components, svd_solver=\"randomized\", whiten=True).fit(X_train)\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão de X_train: (1170, 1850)\n",
      "Dimensão de X_train_pca: (1170, 150)\n",
      "\n",
      "Dimensão de X_test: (390, 1850)\n",
      "Dimensão de X_test_pca: (390, 150)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensão de X_train:\", X_train.shape)\n",
    "print(\"Dimensão de X_train_pca:\", X_train_pca.shape)\n",
    "print(\"\\nDimensão de X_test:\", X_test.shape)\n",
    "print(\"Dimensão de X_test_pca:\", X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar um modelo de classificação por SVM inicial\n",
    "\n",
    "Para comprovar o funcionamento do nosso classificador SVC antes de o otimizar por validação cruzada, vamos formar um modelo inicial sobre o subset de formação e validá-lo sobre o subset de teste.\n",
    "\n",
    "Recordar usar a função [decision_function_shape](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification) para usar o esquema “um contra o resto” (“ovr”). \n",
    "\n",
    "Usar os valores por defeito de *C* e *gamma* para não influir sobre a sua regularização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.414s\n"
     ]
    }
   ],
   "source": [
    "model = SVC(decision_function_shape='ovr')\n",
    "t0 = time()\n",
    "model.fit(X_train_pca, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo no subset de teste\n",
    "Neste caso, não vamos representar a matriz de confusão, pois com 5749 classes seria demasiado grande para o analisar num gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.099s\n"
     ]
    }
   ],
   "source": [
    "# TODO: Avaliar o modelo com o seu score () no subset de teste.\n",
    "t1 = time()\n",
    "y_test_pred = model.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6974358974358974\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Então concluimos que, provavelmente por usar os valores por defeito de C e gamma, não obteve um bom resultado de accuracy nomeadamente de 0.69."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
