{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM: Scikit-learn sobre dataset Labeled Faces in the Wild\n",
    "\n",
    "## O que vamos fazer?\n",
    "- Descarregar e analisar o dataset Labeled Faces in the Wild (LFW). \n",
    "- Pré-processar o dataset.\n",
    "- Formar um modelo de classificação multiclasse com SVM por validação cruzada. \n",
    "- Avaliar a precisão do modelo e representá-la graficamente\n",
    "\n",
    "O dataset Labeled Faces in the Wild (LFW) é um dos datasets mais usados como exemplo e para avaliar os nossos modelos e algoritmos. É um dataset muito curioso: é uma coleção de fotos de rostos de famosos (em formato JPEG) com 13 233 exemplos, 5 749 classes (rostos de famosos) e 5 828 características (pixeis).\n",
    "\n",
    "Toda a informação está na sua página de internet oficial: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "Habitualmente usamos o dataset em 2 tipos de tarefas ou modelos diferentes de classificação:\n",
    "- Verificação de faces: num conjunto de 2 fotografias, um modelo de classificação binária deve prever se é a mesma pessoa.\n",
    "- Reconhecimento facial: numa fotografia, o modelo deve classificá-la como pertencendo a um dos famosos identificados (classes).\n",
    "\n",
    "\n",
    "A sua tarefa será criar um modelo SVM para resolver a tarefa de reconhecimento facial, otimizar os seus hiper-parâmetros por validação cruzada e avaliá-lo.\n",
    "\n",
    "*Vamos formar um modelo ML que seja capaz de reconhecer rostos de famosos!*\n",
    "\n",
    "Referências:\n",
    "- [The Labeled Faces in the Wild face recognition dataset](https://scikit-learn.org/stable/datasets/index.html#labeled-faces-in-the-wild-dataset)\n",
    "- [sklearn.datasets.fetch_lfw_people](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html)\n",
    "- [sklearn.datasets.fetch_lfw_pairs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_pairs.html)\n",
    "- [Faces recognition example using eigenfaces and SVMs](https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar de todos os módulos necessários para esta célula\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from time import time\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar o dataset LFW\n",
    "\n",
    "Representar graficamente alguns dos exemplos e as suas classes ou números associados.\n",
    "\n",
    "*Nota*: Cuidado com o seu tamanho! Se for um dataset demasiado grande para o seu ambiente, pode reduzir o seu tamanho escolhendo um número de exemplos mais reduzido ao acaso, reordenando aleatoriamente os exemplos para evitar ter classes/faces com um número baixo de exemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foi reduzido o Dataset, devido ao facto de ser muito extenso. Apenas faces com no minimo 20 exemplos foram escolhidas e cada imagem foi redimensionada para 30% do tamanho original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exitem 3023 exemplos\n",
      "A imagem tem de tamanho 62 x 47.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Carregar o dataset Digits como arrays X e Y e representar alguns dos exemplos\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=20)#, resize=0.4)  # redimensiona as imagens para 30% do tamanho original\n",
    "\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "print(f\"Exitem {n_samples} exemplos\")\n",
    "print(f\"A imagem tem de tamanho {h} x {w}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamnho do dataset: (3023, 2914)\n",
      "Número de classes: 62\n",
      "Nome das pessoas: ['Alejandro Toledo' 'Alvaro Uribe' 'Amelie Mauresmo' 'Andre Agassi'\n",
      " 'Angelina Jolie' 'Ariel Sharon' 'Arnold Schwarzenegger'\n",
      " 'Atal Bihari Vajpayee' 'Bill Clinton' 'Carlos Menem' 'Colin Powell'\n",
      " 'David Beckham' 'Donald Rumsfeld' 'George Robertson' 'George W Bush'\n",
      " 'Gerhard Schroeder' 'Gloria Macapagal Arroyo' 'Gray Davis'\n",
      " 'Guillermo Coria' 'Hamid Karzai' 'Hans Blix' 'Hugo Chavez' 'Igor Ivanov'\n",
      " 'Jack Straw' 'Jacques Chirac' 'Jean Chretien' 'Jennifer Aniston'\n",
      " 'Jennifer Capriati' 'Jennifer Lopez' 'Jeremy Greenstock' 'Jiang Zemin'\n",
      " 'John Ashcroft' 'John Negroponte' 'Jose Maria Aznar'\n",
      " 'Juan Carlos Ferrero' 'Junichiro Koizumi' 'Kofi Annan' 'Laura Bush'\n",
      " 'Lindsay Davenport' 'Lleyton Hewitt' 'Luiz Inacio Lula da Silva'\n",
      " 'Mahmoud Abbas' 'Megawati Sukarnoputri' 'Michael Bloomberg' 'Naomi Watts'\n",
      " 'Nestor Kirchner' 'Paul Bremer' 'Pete Sampras' 'Recep Tayyip Erdogan'\n",
      " 'Ricardo Lagos' 'Roh Moo-hyun' 'Rudolph Giuliani' 'Saddam Hussein'\n",
      " 'Serena Williams' 'Silvio Berlusconi' 'Tiger Woods' 'Tom Daschle'\n",
      " 'Tom Ridge' 'Tony Blair' 'Vicente Fox' 'Vladimir Putin' 'Winona Ryder']\n"
     ]
    }
   ],
   "source": [
    "X = lfw_people.data\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "\n",
    "print(\"Tamnho do dataset:\", X.shape)\n",
    "print(\"Número de classes:\", len(target_names))\n",
    "print(\"Nome das pessoas:\", target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31764707, 0.35555556, 0.45228758, ..., 0.42222223, 0.5921569 ,\n",
       "        0.49019608],\n",
       "       [0.1385621 , 0.27450982, 0.33464053, ..., 0.23398693, 0.3267974 ,\n",
       "        0.45359477],\n",
       "       [0.33594772, 0.21830066, 0.22745098, ..., 0.69542485, 0.32026145,\n",
       "        0.303268  ],\n",
       "       [0.5555556 , 0.5542484 , 0.4392157 , ..., 0.45359477, 0.4261438 ,\n",
       "        0.43790853],\n",
       "       [0.34901962, 0.38431373, 0.3529412 , ..., 0.8928104 , 0.93202615,\n",
       "        0.94248366]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "Pré-processar os dados com os métodos Scikit-learn:\n",
    "\n",
    "- Reordená-los aleatoriamente. \n",
    "- Normalizar, se necessário.\n",
    "- Dividi-los em subsets de formação e testes.\n",
    "\n",
    "Nesta ocasião, mais uma vez, faremos a validação cruzada por K-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23006536, 0.3150327 , 0.4169935 , ..., 0.5620915 , 0.5503268 ,\n",
       "        0.5673203 ],\n",
       "       [0.24836601, 0.26797387, 0.2379085 , ..., 0.6379085 , 0.6575164 ,\n",
       "        0.6653595 ],\n",
       "       [0.42875817, 0.39346406, 0.35686275, ..., 0.882353  , 0.8366013 ,\n",
       "        0.41568628],\n",
       "       [0.26666668, 0.3137255 , 0.29150328, ..., 0.4928105 , 0.07189543,\n",
       "        0.00261438],\n",
       "       [0.48758173, 0.5503268 , 0.60915035, ..., 0.0627451 , 0.05620915,\n",
       "        0.06143792]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Reordenar os dados aleatoriamente\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar, se necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividi-los em subsets de formação e testes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler() # padronizar os dados para que tenham média 0 e desvio padrão 1\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar um modelo de classificação por SVM inicial\n",
    "\n",
    "Para comprovar o funcionamento do nosso classificador SVC antes de o otimizar por validação cruzada, vamos formar um modelo inicial sobre o subset de formação e validá-lo sobre o subset de teste.\n",
    "\n",
    "Recordar usar a função [decision_function_shape](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification) para usar o esquema “um contra o resto” (“ovr”). \n",
    "\n",
    "Usar os valores por defeito de *C* e *gamma* para não influir sobre a sua regularização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 13.656s\n"
     ]
    }
   ],
   "source": [
    "model = SVC(decision_function_shape='ovr')\n",
    "t0 = time()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo no subset de teste\n",
    "Neste caso, não vamos representar a matriz de confusão, pois com 5749 classes seria demasiado grande para o analisar num gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.781s\n"
     ]
    }
   ],
   "source": [
    "# TODO: Avaliar o modelo com o seu score () no subset de teste.\n",
    "t1 = time()\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39814814814814814\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Então concluimos que, provavelmente por usar os valores por defeito de C e gamma, não obteve um bom resultado de accuracy nomeadamente de 0.68."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
